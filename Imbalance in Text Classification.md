此处的imbalance指类别比 > 1:10

### Class-Imbalance 问题使用的Metrics
Ref:
https://zhuanlan.zhihu.com/p/32940093

0. F1 (推荐)
1. PRC: precision-recall curve, 计算PRC曲线下面积(推荐)
2. ROC：receiver operating curve, 计算ROC曲线下面积
3. Precision@n：将分类阈值设定为恰好召回n个少数类样例时分类器的precision
4. Average precision：平均精度，主要描述了precision的一般表现，在异常检测时会用到

================== 华丽的分割线 =====================

### 采样方法
Ref:
https://www.zhihu.com/question/269698662/answer/352279936  
Package: imbalanced-learn  

1. 集成学习 + 阈值调整(使模型对较少的类别更为敏感)
2. Over-sampling：最大的风险是对少数类的过拟合。如果数据标签中有错误或是噪音，则错误会被成倍放大。
3. Under-sampling：可能会造成bias很大的模型。反复欠采样然后集成的方式效果一般，且少数类被反复使用，也容易造成过拟合。
4. SMOTE：可理解为一种集成学习，降低了方差，但也可能加强局部偶然性，增加过拟合风险。对噪音抵抗性更强。可能会生成一些错误样例。

总结：
    - 采样方法一般比直接调整阈值效果要好
    - 使用采样一般可以提升模型泛化性，但有过拟合风险，应搭配使用正则化模型
    - 过采样结果较为稳定，大多数时候比欠采样效果好，但还是要具体数据分布具体讨论。SMOTE大多数情况和过采样效果相似

================== 华丽的分割线 =====================

### 训练方法
Ref：  
https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247484993&idx=1&sn=0bd32089a638e5a1b48239656febb6e0&chksm=970c2e97a07ba7818d63dddbb469486dccb369ecc11f38ffdea596452b9e5bf65772820a8ac9&token=407616831&lang=zh_CN#rd

0. 使用随机森林或是xgboost
1. 有监督的集成学习：先用采样的方法建立K个balance的训练集，训练K个分类器（使用简单的分类器，如LR），并对K个分类器的结果取平均。在实际使用中，该方法不一定会比集成树模型更好，可能还不如xgboost，但可以尝试一下，说不定有奇效。
2. 无监督的异常检测：把监督学习变为无监督学习，舍弃掉标签把问题转化为一个无监督问题。 无监督的异常检测一般依赖于对于数据的假设，如认为需要检测的广告类文章和正常文章的内容有很大不同，则可假设广告类文章和正常文章间的欧式距离很大。该方法在对数据假设正确的时候效果会比较好，且无需人工标注数据。
3. 半监督异常集成学习：先在原始数据集上用多个无监督异常检测方法抽取数据表示，并和原始数据结合作为新的特征空间，再在其上使用集成树模型，如xgboost进行监督学习。无监督异常检测的目的是提高原始数据表达，监督集成树的目的是减低数据不平衡对最终预测结果的影响。该方法的问题是运算开销比较大。
4. 高维数据上的半监督异常检测：KDD
5. 对数据先进行聚类，再将大的簇进行随机欠采样或者小的簇进行数据生成

建议尝试顺序：0-5-1-2-3-4

